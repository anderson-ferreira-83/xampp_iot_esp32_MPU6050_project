{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - EDA v3: Spectral Features (P1-P14)\n",
    "\n",
    "Análise espectral via FFT + treino GNB com features combinadas (temporal + espectral).\n",
    "\n",
    "- **Objetivo**: Melhorar separabilidade LOW vs MEDIUM\n",
    "- **Pipeline**: 14 features espectrais (P1-P14) × 6 eixos = 84 features adicionais\n",
    "- **Nota**: Com dados a 5Hz, Nyquist=2.5Hz (limitado). Retreinar com 20Hz para produção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from scipy import stats as scipy_stats\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "SAMPLE_RATE = 5  # Hz (trocar para 20 com coleta 20Hz)\n",
    "WINDOW_SIZE = 100\n",
    "STEP_SIZE = 20\n",
    "\n",
    "print(f'Sample rate: {SAMPLE_RATE} Hz, Nyquist: {SAMPLE_RATE/2} Hz')\n",
    "print(f'Window: {WINDOW_SIZE} pts = {WINDOW_SIZE/SAMPLE_RATE:.1f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Funções: Features Temporais + Espectrais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_features(signal, sample_rate):\n",
    "    \"\"\"Compute P1-P14 spectral features. Identical to JS implementation.\"\"\"\n",
    "    signal = np.asarray(signal, dtype=np.float64)\n",
    "    N = int(2 ** np.ceil(np.log2(len(signal))))\n",
    "    fft_vals = np.fft.rfft(signal, n=N)\n",
    "    mag = np.abs(fft_vals) / N\n",
    "    mag[1:-1] *= 2\n",
    "    freq = np.fft.rfftfreq(N, d=1.0 / sample_rate)\n",
    "\n",
    "    mag_ndc = mag[1:]\n",
    "    freq_ndc = freq[1:]\n",
    "    sumS = mag_ndc.sum()\n",
    "\n",
    "    if sumS < 1e-15:\n",
    "        return {f'P{i}': 0.0 for i in range(1, 15)}\n",
    "\n",
    "    w = mag_ndc / sumS\n",
    "    wf = np.sum(w * freq_ndc)\n",
    "    wf2 = np.sum(w * freq_ndc**2)\n",
    "    wf4 = np.sum(w * freq_ndc**4)\n",
    "\n",
    "    P5 = wf\n",
    "    P1 = P5\n",
    "    P7 = np.sqrt(wf2)\n",
    "\n",
    "    d = freq_ndc - P5\n",
    "    var_ = np.sum(w * d**2)\n",
    "    m3 = np.sum(w * d**3)\n",
    "    m4 = np.sum(w * d**4)\n",
    "    sqrtAbsDev = np.sum(w * np.sqrt(np.abs(d)))\n",
    "\n",
    "    P2 = var_\n",
    "    P6 = np.sqrt(P2)\n",
    "    P14 = P6\n",
    "    P3 = m3 / (P6**3) if P6 > 1e-15 else 0.0\n",
    "    P4 = m4 / (P6**4) if P6 > 1e-15 else 0.0\n",
    "    P8 = np.sqrt(np.sqrt(wf4 / wf2)) if wf2 > 1e-15 else 0.0\n",
    "    P9 = wf2 / (P5**2) if P5 > 1e-15 else 0.0\n",
    "    P10 = P6 / P5 if P5 > 1e-15 else 0.0\n",
    "    P11 = P3\n",
    "    P12 = P4\n",
    "    P13 = sqrtAbsDev**2\n",
    "\n",
    "    return {'P1': P1, 'P2': P2, 'P3': P3, 'P4': P4, 'P5': P5,\n",
    "            'P6': P6, 'P7': P7, 'P8': P8, 'P9': P9, 'P10': P10,\n",
    "            'P11': P11, 'P12': P12, 'P13': P13, 'P14': P14}\n",
    "\n",
    "\n",
    "def axis_features(arr, prefix):\n",
    "    \"\"\"11 temporal features for one axis (aligned with JS).\"\"\"\n",
    "    vals = np.asarray(arr, dtype=np.float64)\n",
    "    n = len(vals)\n",
    "    m = vals.mean()\n",
    "    s = vals.std(ddof=0)\n",
    "    rms = np.sqrt((vals**2).mean())\n",
    "    abs_vals = np.abs(vals)\n",
    "    abs_sorted = np.sort(abs_vals)\n",
    "    peak = abs_sorted[int(0.95 * (n - 1))]\n",
    "    mean_abs = abs_vals.mean()\n",
    "    root_amp = (np.sqrt(abs_vals).mean())**2\n",
    "    skew_val = scipy_stats.skew(vals, bias=True) if n >= 3 else 0.0\n",
    "    kurt_val = scipy_stats.kurtosis(vals, fisher=True, bias=True) if n >= 4 else 0.0\n",
    "    crest = peak / rms if rms > 1e-10 else 0.0\n",
    "    shape = rms / mean_abs if mean_abs > 1e-10 else 0.0\n",
    "    impulse = peak / mean_abs if mean_abs > 1e-10 else 0.0\n",
    "    clearance = peak / root_amp if root_amp > 1e-10 else 0.0\n",
    "    return {\n",
    "        f'{prefix}_mean': m, f'{prefix}_std': s, f'{prefix}_skew': skew_val,\n",
    "        f'{prefix}_kurtosis': kurt_val, f'{prefix}_rms': rms, f'{prefix}_peak': peak,\n",
    "        f'{prefix}_root_amplitude': root_amp, f'{prefix}_crest_factor': crest,\n",
    "        f'{prefix}_shape_factor': shape, f'{prefix}_impulse_factor': impulse,\n",
    "        f'{prefix}_clearance_factor': clearance,\n",
    "    }\n",
    "\n",
    "\n",
    "AXES = ['accel_x_g', 'accel_y_g', 'accel_z_g', 'gyro_x_dps', 'gyro_y_dps', 'gyro_z_dps']\n",
    "\n",
    "def extract_all_features(window, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"Extract 66 temporal + 84 spectral = 150 features.\"\"\"\n",
    "    features = {}\n",
    "    for ax in AXES:\n",
    "        vals = window[ax].values\n",
    "        features.update(axis_features(vals, ax))\n",
    "        if sample_rate and sample_rate > 0:\n",
    "            spec = compute_spectral_features(vals, sample_rate)\n",
    "            for k, v in spec.items():\n",
    "                features[f'{ax}_{k}'] = v\n",
    "    return features\n",
    "\n",
    "print(f'Features per window: 66 temporal + 84 spectral = 150')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentar carregar do DB primeiro, fallback para CSV\n",
    "try:\n",
    "    from sqlalchemy import create_engine\n",
    "    engine = create_engine('mysql+mysqlconnector://root:@localhost/iot_mpu6050')\n",
    "    query = \"SELECT * FROM sensor_data WHERE fan_state IN ('LOW','MEDIUM','HIGH') ORDER BY timestamp ASC\"\n",
    "    df_raw = pd.read_sql(query, engine)\n",
    "    print(f'Dados do DB: {len(df_raw)} linhas')\n",
    "except Exception as e:\n",
    "    print(f'DB indisponível ({e}), carregando CSV...')\n",
    "    csv_path = 'output/data/features_latest.csv'\n",
    "    if not os.path.exists(csv_path):\n",
    "        csv_path = 'output/data/raw_sensor_data_20260131_210511.csv'\n",
    "    df_raw = pd.read_csv(csv_path)\n",
    "    print(f'CSV carregado: {len(df_raw)} linhas')\n",
    "\n",
    "print(f'Classes: {df_raw[\"fan_state\"].value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering (Temporal + Espectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list, y_list = [], []\n",
    "\n",
    "for state in ['LOW', 'MEDIUM', 'HIGH']:\n",
    "    df_state = df_raw[df_raw['fan_state'] == state].reset_index(drop=True)\n",
    "    if len(df_state) < WINDOW_SIZE:\n",
    "        print(f'{state}: insuficiente ({len(df_state)})')\n",
    "        continue\n",
    "    for i in range(WINDOW_SIZE, len(df_state), STEP_SIZE):\n",
    "        w = df_state.iloc[i-WINDOW_SIZE:i]\n",
    "        feats = extract_all_features(w, SAMPLE_RATE)\n",
    "        X_list.append(feats)\n",
    "        y_list.append(state)\n",
    "\n",
    "X = pd.DataFrame(X_list)\n",
    "y = np.array(y_list)\n",
    "\n",
    "temporal_cols = [c for c in X.columns if '_P' not in c.split('_')[-1]]\n",
    "spectral_cols = [c for c in X.columns if '_P' in c]\n",
    "\n",
    "print(f'Dataset: {len(X)} amostras, {len(X.columns)} features')\n",
    "print(f'  Temporais: {len(temporal_cols)}, Espectrais: {len(spectral_cols)}')\n",
    "print(f'  Distribuição: {pd.Series(y).value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualização Espectral (FFT médio por classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes_plot = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes_plot = axes_plot.flatten()\n",
    "colors = {'LOW': 'blue', 'MEDIUM': 'orange', 'HIGH': 'red'}\n",
    "\n",
    "for idx, ax_name in enumerate(AXES):\n",
    "    ax = axes_plot[idx]\n",
    "    for state in ['LOW', 'MEDIUM', 'HIGH']:\n",
    "        df_state = df_raw[df_raw['fan_state'] == state].reset_index(drop=True)\n",
    "        if len(df_state) < WINDOW_SIZE:\n",
    "            continue\n",
    "        # Average FFT over windows\n",
    "        all_mags = []\n",
    "        for i in range(WINDOW_SIZE, min(len(df_state), WINDOW_SIZE + STEP_SIZE * 20), STEP_SIZE):\n",
    "            sig = df_state[ax_name].iloc[i-WINDOW_SIZE:i].values\n",
    "            N = int(2 ** np.ceil(np.log2(len(sig))))\n",
    "            fft_v = np.fft.rfft(sig, n=N)\n",
    "            mag = np.abs(fft_v) / N\n",
    "            mag[1:-1] *= 2\n",
    "            all_mags.append(mag)\n",
    "        avg_mag = np.mean(all_mags, axis=0)\n",
    "        freq = np.fft.rfftfreq(N, d=1.0/SAMPLE_RATE)\n",
    "        ax.plot(freq[1:], avg_mag[1:], label=state, color=colors[state], alpha=0.8)\n",
    "    ax.set_title(ax_name)\n",
    "    ax.set_xlabel('Freq (Hz)')\n",
    "    ax.set_ylabel('Magnitude')\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle(f'FFT Médio por Classe (SR={SAMPLE_RATE}Hz, Nyquist={SAMPLE_RATE/2}Hz)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/04_fft_medio_por_classe.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ANOVA Ranking (150 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "anova_results = []\n",
    "for col in X.columns:\n",
    "    groups = [X[col][y == c].values for c in ['LOW', 'MEDIUM', 'HIGH']]\n",
    "    if all(len(g) > 1 for g in groups):\n",
    "        f_stat, p_val = f_oneway(*groups)\n",
    "        anova_results.append({'feature': col, 'f_statistic': f_stat, 'p_value': p_val,\n",
    "                              'is_spectral': '_P' in col})\n",
    "\n",
    "df_anova = pd.DataFrame(anova_results).sort_values('f_statistic', ascending=False)\n",
    "df_sig = df_anova[df_anova['p_value'] < 0.05]\n",
    "\n",
    "print(f'Features significativas (p<0.05): {len(df_sig)}/{len(df_anova)}')\n",
    "print(f'  Temporais: {len(df_sig[~df_sig[\"is_spectral\"]])}')\n",
    "print(f'  Espectrais: {len(df_sig[df_sig[\"is_spectral\"]])}')\n",
    "print(f'\\nTop 20 features:')\n",
    "df_sig.head(20)[['feature', 'f_statistic', 'p_value', 'is_spectral']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Separabilidade LOW vs MEDIUM (SNR por feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_results = []\n",
    "for col in X.columns:\n",
    "    low = X[col][y == 'LOW']\n",
    "    med = X[col][y == 'MEDIUM']\n",
    "    mean_diff = abs(low.mean() - med.mean())\n",
    "    pooled_std = np.sqrt((low.std()**2 + med.std()**2) / 2)\n",
    "    snr = mean_diff / pooled_std if pooled_std > 1e-10 else 0\n",
    "    snr_results.append({'feature': col, 'snr_low_med': snr, 'is_spectral': '_P' in col})\n",
    "\n",
    "df_snr = pd.DataFrame(snr_results).sort_values('snr_low_med', ascending=False)\n",
    "print('Top 20 features para separar LOW vs MEDIUM (SNR):')\n",
    "df_snr.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Seleção de Features (Conjuntos D, E, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significativas com p < 0.05\n",
    "sig_features = set(df_sig['feature'].values)\n",
    "\n",
    "# Remove highly correlated (>0.85) - keep higher ANOVA\n",
    "def remove_correlated(feature_list, X_data, threshold=0.85):\n",
    "    corr = X_data[feature_list].corr().abs()\n",
    "    anova_rank = {f: i for i, f in enumerate(df_anova['feature'].values)}\n",
    "    to_drop = set()\n",
    "    for i in range(len(feature_list)):\n",
    "        for j in range(i+1, len(feature_list)):\n",
    "            if corr.iloc[i, j] > threshold:\n",
    "                fi, fj = feature_list[i], feature_list[j]\n",
    "                # Drop the one with lower ANOVA rank\n",
    "                drop = fj if anova_rank.get(fi, 999) < anova_rank.get(fj, 999) else fi\n",
    "                to_drop.add(drop)\n",
    "    return [f for f in feature_list if f not in to_drop]\n",
    "\n",
    "# D: Temporal top (baseline)\n",
    "temporal_sig = [f for f in df_anova['feature'].values if f in sig_features and '_P' not in f]\n",
    "set_D = remove_correlated(temporal_sig[:20], X)\n",
    "\n",
    "# E: Spectral top\n",
    "spectral_sig = [f for f in df_anova['feature'].values if f in sig_features and '_P' in f]\n",
    "set_E = remove_correlated(spectral_sig[:20], X)\n",
    "\n",
    "# F: Combined best\n",
    "combined_sig = [f for f in df_anova['feature'].values if f in sig_features][:30]\n",
    "set_F = remove_correlated(combined_sig, X)\n",
    "\n",
    "print(f'Set D (temporal): {len(set_D)} features')\n",
    "print(f'Set E (spectral): {len(set_E)} features')\n",
    "print(f'Set F (combined): {len(set_F)} features')\n",
    "print(f'\\nSet F: {set_F}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Treino GNB: Comparar D / E / F (CV 5-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = {}\n",
    "\n",
    "for name, feature_set in [('D (temporal)', set_D), ('E (spectral)', set_E), ('F (combined)', set_F)]:\n",
    "    if not feature_set:\n",
    "        print(f'{name}: sem features significativas')\n",
    "        continue\n",
    "    clf = GaussianNB()\n",
    "    scores = cross_val_score(clf, X[feature_set], y, cv=cv, scoring='accuracy')\n",
    "    results[name] = scores\n",
    "    print(f'{name}: {scores.mean()*100:.2f}% ± {scores.std()*100:.2f}% ({len(feature_set)} features)')\n",
    "\n",
    "# Select best set\n",
    "best_name = max(results, key=lambda k: results[k].mean())\n",
    "best_features = {'D (temporal)': set_D, 'E (spectral)': set_E, 'F (combined)': set_F}[best_name]\n",
    "print(f'\\nMelhor: {best_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_final = GaussianNB()\n",
    "clf_final.fit(X[best_features], y)\n",
    "y_pred = clf_final.predict(X[best_features])\n",
    "\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y, y_pred, labels=['LOW', 'MEDIUM', 'HIGH'])\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['LOW', 'MEDIUM', 'HIGH'],\n",
    "            yticklabels=['LOW', 'MEDIUM', 'HIGH'], ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title(f'Confusion Matrix - {best_name}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/04_confusion_matrix_spectral.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Simulação de Transição (Simetria H→L vs L→H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular transição: construir janelas que cruzam fronteira entre estados\n",
    "transitions = [('LOW', 'HIGH'), ('HIGH', 'LOW'), ('LOW', 'MEDIUM'), ('MEDIUM', 'LOW')]\n",
    "\n",
    "for from_state, to_state in transitions:\n",
    "    df_from = df_raw[df_raw['fan_state'] == from_state].tail(WINDOW_SIZE // 2)\n",
    "    df_to = df_raw[df_raw['fan_state'] == to_state].head(WINDOW_SIZE // 2)\n",
    "    if len(df_from) < WINDOW_SIZE // 2 or len(df_to) < WINDOW_SIZE // 2:\n",
    "        print(f'{from_state}→{to_state}: dados insuficientes')\n",
    "        continue\n",
    "    mixed = pd.concat([df_from, df_to]).reset_index(drop=True)\n",
    "    feats = extract_all_features(mixed, SAMPLE_RATE)\n",
    "    feats_s = pd.DataFrame([feats])\n",
    "    pred = clf_final.predict(feats_s[best_features])\n",
    "    proba = clf_final.predict_proba(feats_s[best_features])\n",
    "    print(f'{from_state}→{to_state}: pred={pred[0]}, proba={dict(zip(clf_final.classes_, proba[0].round(3)))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Exportação: Modelo JSON + feature_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model JSON\n",
    "train_acc = accuracy_score(y, y_pred)\n",
    "cv_scores = cross_val_score(clf_final, X[best_features], y, cv=5)\n",
    "\n",
    "model_data = {\n",
    "    'type': 'gaussian_nb',\n",
    "    'version': '5.0_spectral',\n",
    "    'generated_at': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'sample_rate_hz': SAMPLE_RATE,\n",
    "    'features': list(best_features),\n",
    "    'labels': list(clf_final.classes_),\n",
    "    'priors': {label: float(clf_final.class_prior_[i]) for i, label in enumerate(clf_final.classes_)},\n",
    "    'stats': {},\n",
    "    'metrics': {\n",
    "        'train_accuracy': float(train_acc),\n",
    "        'cv_accuracy_mean': float(cv_scores.mean()),\n",
    "        'cv_accuracy_std': float(cv_scores.std()),\n",
    "    },\n",
    "    'training_info': {\n",
    "        'total_samples': int(len(X)),\n",
    "        'window_size': WINDOW_SIZE,\n",
    "        'step_size': STEP_SIZE,\n",
    "        'feature_set': best_name,\n",
    "        'n_temporal': len([f for f in best_features if '_P' not in f]),\n",
    "        'n_spectral': len([f for f in best_features if '_P' in f]),\n",
    "    }\n",
    "}\n",
    "\n",
    "for i, label in enumerate(clf_final.classes_):\n",
    "    model_data['stats'][label] = {}\n",
    "    for j, feat in enumerate(best_features):\n",
    "        model_data['stats'][label][feat] = {\n",
    "            'mean': float(clf_final.theta_[i, j]),\n",
    "            'var': float(clf_final.var_[i, j])\n",
    "        }\n",
    "\n",
    "timestamp = time.strftime('%Y%m%d')\n",
    "model_path = f'output/models/gnb_model_spectral_{timestamp}.json'\n",
    "os.makedirs('output/models', exist_ok=True)\n",
    "with open(model_path, 'w') as f:\n",
    "    json.dump(model_data, f, indent=2)\n",
    "\n",
    "# Also save to project models/\n",
    "model_path2 = f'../models/gnb_model_spectral_{timestamp}.json'\n",
    "with open(model_path2, 'w') as f:\n",
    "    json.dump(model_data, f, indent=2)\n",
    "\n",
    "print(f'Modelo exportado: {model_path}')\n",
    "print(f'Modelo exportado: {model_path2}')\n",
    "print(f'Features: {len(best_features)} ({best_name})')\n",
    "print(f'Acurácia CV: {cv_scores.mean()*100:.2f}% ± {cv_scores.std()*100:.2f}%')\n",
    "\n",
    "# Update feature_config.json\n",
    "config_path = '../config/feature_config.json'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config['version'] = '5.0'\n",
    "config['selected_features'] = list(best_features)\n",
    "config['feature_count'] = len(best_features)\n",
    "config['generated_at'] = time.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f'Config atualizado: {config_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
