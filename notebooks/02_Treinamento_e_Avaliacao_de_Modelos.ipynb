{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Treinamento e Avaliação de Modelos\n",
    "\n",
    "**Objetivo:** Este notebook utiliza o conhecimento da análise exploratória para treinar, avaliar e comparar diferentes modelos de Machine Learning, com o objetivo de encontrar o classificador mais preciso e robusto para o nosso problema.\n",
    "\n",
    "**Etapas:**\n",
    "1.  **Configuração e Preparação dos Dados**: Carrega os dados e aplica a engenharia de features desenvolvida no notebook anterior.\n",
    "2.  **Divisão de Dados**: Separa os dados em conjuntos de treino e teste para uma avaliação imparcial.\n",
    "3.  **Seleção de Features**: Define um subconjunto de features para treinar um modelo mais simples e eficiente.\n",
    "4.  **Divisão de Dados**: Separa os dados em conjuntos de treino e teste para uma avaliação imparcial.\n",
    "5.  **Modelo de Base (Gaussian Naive Bayes)**: Treina e avalia o modelo atual para estabelecer uma linha de base de performance.\n",
    "6.  **Experimentação com Modelos Avançados**: Treina e avalia `Random Forest` e `LightGBM` para buscar uma performance superior.\n",
    "7.  **Comparação e Seleção**: Compara a performance de todos os modelos usando validação cruzada para escolher o melhor.\n",
    "8.  **Análise de Importância das Features**: Investiga quais features mais contribuíram para a decisão do melhor modelo.\n",
    "9.  **Treinamento e Exportação do Modelo Final**: Treina o modelo `GaussianNB` com todos os dados e o exporta no formato correto para uso no dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Modelos e Ferramentas de Avaliação\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- CONFIGURAÇÕES ---\n",
    "\n",
    "# Conexão com o banco de dados\n",
    "DB_CONNECTION_STR = 'mysql+mysqlconnector://root:@localhost/iot_mpu6050'\n",
    "\n",
    "# Parâmetros da Engenharia de Features\n",
    "WINDOW_SIZE = 100  # Tamanho da janela deslizante\n",
    "STEP = 20          # Passo da janela\n",
    "\n",
    "# Diretório para salvar o modelo treinado\n",
    "PATH_MODELS = 'output/models/'\n",
    "os.makedirs(PATH_MODELS, exist_ok=True)\n",
    "\n",
    "# Configurações visuais\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "print(\"Ambiente configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função é a mesma do notebook 01_Analise_Exploratoria\n",
    "# Ela transforma os dados brutos do sinal em features estatísticas\n",
    "\n",
    "def extract_time_domain_features(series):\n",
    "    \"\"\"Calcula um conjunto de features de domínio do tempo para uma série de dados.\"\"\"\n",
    "    series = series.dropna()\n",
    "    if series.empty:\n",
    "        return pd.Series(dtype='float64')\n",
    "\n",
    "    # Métricas básicas\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    \n",
    "    # Métricas de amplitude\n",
    "    rms = np.sqrt(np.mean(series**2))\n",
    "    peak = series.abs().max()\n",
    "    root_amplitude = (np.mean(np.sqrt(series.abs())))**2\n",
    "    mean_abs = series.abs().mean()\n",
    "\n",
    "    # Fatores de forma (evitar divisão por zero)\n",
    "    crest_factor = peak / rms if rms > 0 else 0\n",
    "    shape_factor = rms / mean_abs if mean_abs > 0 else 0\n",
    "    impulse_factor = peak / mean_abs if mean_abs > 0 else 0\n",
    "    clearance_factor = peak / root_amplitude if root_amplitude > 0 else 0\n",
    "\n",
    "    return pd.Series({\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'skew': skew(series),\n",
    "        'kurtosis': kurtosis(series),\n",
    "        'rms': rms,\n",
    "        'peak': peak,\n",
    "        'root_amplitude': root_amplitude,\n",
    "        'crest_factor': crest_factor,\n",
    "        'shape_factor': shape_factor,\n",
    "        'impulse_factor': impulse_factor,\n",
    "        'clearance_factor': clearance_factor\n",
    "    })\n",
    "\n",
    "print(\"Função extract_time_domain_features definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [1/9] Carregando e Processando Dados ---\")\n",
    "\n",
    "# 1. Carregar dados do banco\n",
    "try:\n",
    "    engine = create_engine(DB_CONNECTION_STR)\n",
    "    query = \"SELECT * FROM sensor_data WHERE fan_state IN ('LOW', 'MEDIUM', 'HIGH') ORDER BY timestamp ASC\"\n",
    "    df_raw = pd.read_sql(query, engine)\n",
    "    print(f\"✅ Dados brutos carregados: {len(df_raw)} linhas.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO AO CARREGAR DADOS: {e}\")\n",
    "    df_raw = pd.DataFrame()\n",
    "\n",
    "# 2. Aplicar Engenharia de Features (Janela Deslizante)\n",
    "all_window_features = []\n",
    "if not df_raw.empty:\n",
    "    sensor_axes = ['accel_x_g', 'accel_y_g', 'accel_z_g', 'gyro_x_dps', 'gyro_y_dps', 'gyro_z_dps']\n",
    "    \n",
    "    for state in df_raw['fan_state'].unique():\n",
    "        df_state = df_raw[df_raw['fan_state'] == state].reset_index(drop=True)\n",
    "        if len(df_state) < WINDOW_SIZE:\n",
    "            continue\n",
    "        \n",
    "        print(f'Processando classe \"{state}\"...')\n",
    "        for i in range(0, len(df_state) - WINDOW_SIZE + 1, STEP):\n",
    "            window = df_state.iloc[i : i + WINDOW_SIZE]\n",
    "            \n",
    "            features_for_window = {'fan_state': state}\n",
    "            for axis in sensor_axes:\n",
    "                features_for_axis = extract_time_domain_features(window[axis])\n",
    "                for feature_name, value in features_for_axis.items():\n",
    "                    features_for_window[f'{axis}_{feature_name}'] = value\n",
    "            \n",
    "            all_window_features.append(features_for_window)\n",
    "\n",
    "    df_features = pd.DataFrame(all_window_features)\n",
    "    print(f\"\\n✅ Dataset de Features Criado: {df_features.shape[0]} amostras, {df_features.shape[1]-1} features.\")\n",
    "    display(df_features.head())\n",
    "else:\n",
    "    df_features = pd.DataFrame()\n",
    "    print(\"Nenhum dado para processar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [3/9] Seleção de Features ---\")\n",
    "\n",
    "# Com base na análise de importância do notebook 01, podemos selecionar um subconjunto de features.\n",
    "# Deixe a lista VAZIA para usar TODAS as 66 features.\n",
    "# Preencha com os nomes das features para treinar um modelo mais simples.\n",
    "\n",
    "# Exemplo com as 10 features mais importantes identificadas pelo RandomForest\n",
    "TOP_10_FEATURES = [\n",
    "    'gyro_z_dps_std',\n",
    "    'gyro_z_dps_rms',\n",
    "    'gyro_y_dps_std',\n",
    "    'gyro_y_dps_rms',\n",
    "    'gyro_z_dps_peak',\n",
    "    'gyro_y_dps_peak',\n",
    "    'accel_x_g_std',\n",
    "    'gyro_z_dps_root_amplitude',\n",
    "    'accel_y_g_std',\n",
    "    'gyro_x_dps_std'\n",
    "]\n",
    "\n",
    "# Use esta variável para controlar o treinamento.\n",
    "# Para usar todas, comente a linha abaixo e descomente a seguinte.\n",
    "SELECTED_FEATURES = TOP_10_FEATURES\n",
    "# SELECTED_FEATURES = [] \n",
    "\n",
    "if SELECTED_FEATURES:\n",
    "    print(f\"✅ Usando um subconjunto de {len(SELECTED_FEATURES)} features selecionadas.\")\n",
    "else:\n",
    "    print(\"✅ Usando todas as features disponíveis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [4/9] Dividindo Dados em Treino e Teste ---\")\n",
    "\n",
    "if not df_features.empty:\n",
    "    # Separa as features (X) do rótulo (y)\n",
    "    X = df_features.drop('fan_state', axis=1)\n",
    "    y = df_features['fan_state']\n",
    "    \n",
    "    # Aplica a seleção de features se a lista estiver preenchida\n",
    "    if SELECTED_FEATURES:\n",
    "        # Garante que todas as features selecionadas existem no DataFrame\n",
    "        existing_selected_features = [f for f in SELECTED_FEATURES if f in X.columns]\n",
    "        if len(existing_selected_features) != len(SELECTED_FEATURES):\n",
    "            print(\"⚠️ Aviso: Algumas features selecionadas não foram encontradas no DataFrame gerado.\")\n",
    "        \n",
    "        X = X[existing_selected_features]\n",
    "        print(f\"\\nDataset filtrado para {X.shape[1]} features.\")\n",
    "\n",
    "    # Converte rótulos de texto para números (ex: 'LOW' -> 0), necessário para alguns modelos\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Divide os dados (80% para treino, 20% para teste)\n",
    "    # stratify=y garante que a proporção de classes seja a mesma nos dois conjuntos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "\n",
    "    print(f\"Tamanho do conjunto de treino: {len(X_train)}\")\n",
    "    print(f\"Tamanho do conjunto de teste:  {len(X_test)}\")\n",
    "    print(f\"Classes: {label_encoder.classes_}\")\n",
    "else:\n",
    "    print(\"DataFrame de features vazio. Não é possível dividir os dados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"Plota uma matriz de confusão visualmente clara.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Matriz de Confusão', fontsize=16)\n",
    "    plt.ylabel('Classe Verdadeira', fontsize=12)\n",
    "    plt.xlabel('Classe Prevista', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, class_names):\n",
    "    \"\"\"Faz previsões, calcula métricas e plota a matriz de confusão.\"\"\"\n",
    "    print(f\"--- Avaliando Modelo: {model.__class__.__name__} ---\")\n",
    "    \n",
    "    # Faz previsões no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcula a acurácia\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Acurácia no Teste: {accuracy * 100:.2f}%\\n\")\n",
    "    \n",
    "    # Mostra o relatório de classificação (precisão, recall, f1-score)\n",
    "    print(\"Relatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "    \n",
    "    # Plota a matriz de confusão\n",
    "    plot_confusion_matrix(y_test, y_pred, class_names)\n",
    "\n",
    "print(\"Funções auxiliares de avaliação definidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [5/9] Treinando e Avaliando o Modelo de Base ---\")\n",
    "\n",
    "if 'X_train' in locals():\n",
    "    # Inicializa e treina o modelo\n",
    "    gnb_model = GaussianNB()\n",
    "    gnb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Avalia o modelo\n",
    "    evaluate_model(gnb_model, X_test, y_test, label_encoder.classes_)\n",
    "else:\n",
    "    print(\"Conjunto de treino não definido.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [6/9] Treinando e Avaliando o Modelo Random Forest ---\")\n",
    "\n",
    "if 'X_train' in locals():\n",
    "    # Inicializa e treina o modelo\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Avalia o modelo\n",
    "    evaluate_model(rf_model, X_test, y_test, label_encoder.classes_)\n",
    "else:\n",
    "    print(\"Conjunto de treino não definido.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [6/9] Treinando e Avaliando o Modelo LightGBM ---\")\n",
    "\n",
    "if 'X_train' in locals():\n",
    "    # Inicializa e treina o modelo\n",
    "    lgbm_model = lgb.LGBMClassifier(random_state=42)\n",
    "    lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Avalia o modelo\n",
    "    evaluate_model(lgbm_model, X_test, y_test, label_encoder.classes_)\n",
    "else:\n",
    "    print(\"Conjunto de treino não definido.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [7/9] Comparando Modelos com Validação Cruzada ---\")\n",
    "\n",
    "if 'X' in locals():\n",
    "    models = {\n",
    "        'GaussianNB': GaussianNB(),\n",
    "        'RandomForest': RandomForestClassifier(random_state=42),\n",
    "        'LightGBM': lgb.LGBMClassifier(random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        # cv=5 significa que os dados serão divididos 5 vezes\n",
    "        scores = cross_val_score(model, X, y_encoded, cv=5, scoring='accuracy')\n",
    "        results[name] = scores.mean()\n",
    "        print(f\"Acurácia Média (CV) para {name}: {results[name] * 100:.2f}%\")\n",
    "\n",
    "    # Plotar comparação\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=list(results.keys()), y=list(results.values()))\n",
    "    plt.title('Comparação de Acurácia dos Modelos (Validação Cruzada)', fontsize=16)\n",
    "    plt.ylabel('Acurácia Média', fontsize=12)\n",
    "    plt.ylim(0.8, 1.0)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Dataset completo não definido.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [8/9] Analisando a Importância das Features ---\")\n",
    "\n",
    "# Usaremos o modelo Random Forest, que já foi treinado, para esta análise\n",
    "if 'rf_model' in locals():\n",
    "    importances = rf_model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Cria um DataFrame para facilitar a ordenação e plotagem\n",
    "    feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # Plota as 20 features mais importantes\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importance_df.head(20), palette='viridis')\n",
    "    plt.title('Top 20 Features Mais Importantes (Random Forest)', fontsize=16)\n",
    "    plt.xlabel('Importância', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Modelo Random Forest não foi treinado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [9/9] Treinando e Exportando o Modelo Final para o Dashboard ---\")\n",
    "\n",
    "def export_gaussian_nb_model(model, features, labels, output_path):\n",
    "    \"\"\"Exporta um modelo GaussianNB treinado no formato JSON compatível com o classifier.js\"\"\"\n",
    "    \n",
    "    # Calcula métricas finais\n",
    "    train_acc = accuracy_score(y_encoded, model.predict(X))\n",
    "    cv_scores = cross_val_score(model, X, y_encoded, cv=5)\n",
    "    \n",
    "    export_data = {\n",
    "        \"type\": \"gaussian_nb\",\n",
    "        \"version\": f\"py_{time.strftime('%Y%m%d')}\",\n",
    "        \"generated_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"features\": features,\n",
    "        \"labels\": list(labels),\n",
    "        \"priors\": {},\n",
    "        \"stats\": {},\n",
    "        \"metrics\": {\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"cv_accuracy_mean\": cv_scores.mean()\n",
    "        },\n",
    "        \"training_info\": {\n",
    "            \"total_samples\": len(X),\n",
    "            \"window_size\": WINDOW_SIZE\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Preenche Priors\n",
    "    if hasattr(model, 'class_prior_'):\n",
    "        priors = model.class_prior_\n",
    "    else:\n",
    "        priors = model.class_count_ / model.class_count_.sum()\n",
    "        \n",
    "    for i, label in enumerate(labels):\n",
    "        export_data[\"priors\"][label] = priors[i]\n",
    "        \n",
    "    # Preenche Stats (Médias e Variâncias)\n",
    "    # Estrutura: stats[LABEL][FEATURE] = { mean: ..., var: ... }\n",
    "    for i, label in enumerate(labels):\n",
    "        export_data[\"stats\"][label] = {}\n",
    "        for j, feature in enumerate(features):\n",
    "            export_data[\"stats\"][label][feature] = {\n",
    "                \"mean\": model.theta_[i, j],\n",
    "                \"var\": model.var_[i, j]\n",
    "            }\n",
    "            \n",
    "    # Salva o arquivo\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    print(f\"✅ Modelo exportado com sucesso para: {os.path.abspath(output_path)}\")\n",
    "\n",
    "\n",
    "if 'X' in locals():\n",
    "    # NOTA: Embora Random Forest seja provavelmente melhor, o frontend atual só suporta GaussianNB.\n",
    "    # Portanto, vamos treinar o GNB com todos os dados e exportá-lo.\n",
    "    print(\"Treinando modelo GaussianNB final com todos os dados...\")\n",
    "    final_gnb_model = GaussianNB()\n",
    "    final_gnb_model.fit(X, y_encoded)\n",
    "    \n",
    "    # Define o nome do arquivo de saída\n",
    "    output_filename = f\"gnb_model_{time.strftime('%Y%m%d')}.json\"\n",
    "    output_filepath = os.path.join(PATH_MODELS, output_filename)\n",
    "    \n",
    "    # Exporta o modelo\n",
    "    export_gaussian_nb_model(final_gnb_model, list(X.columns), label_encoder.classes_, output_filepath)\n",
    "    \n",
    "    print(\"\\n--- Próximos Passos ---\")\n",
    "    print(\"1. O novo modelo foi salvo na pasta 'output/models/'.\")\n",
    "    print(\"2. Copie este arquivo para a pasta 'models/' na raiz do projeto.\")\n",
    "    print(f\"3. Atualize a constante 'MODEL_URL' no arquivo 'js/dashboard.js' para: 'models/{output_filename}'\")\n",
    "\n",
    "else:\n",
    "    print(\"Dataset não foi criado. Não é possível treinar ou exportar o modelo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}